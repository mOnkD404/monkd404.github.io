<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>DTech</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="DTech">
<meta property="og:url" content="https://bathingsun.xyz/index.html">
<meta property="og:site_name" content="DTech">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="MonkD404">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="DTech" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">DTech</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://bathingsun.xyz"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-如何调教一台完美测试机" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/10/%E5%A6%82%E4%BD%95%E8%B0%83%E6%95%99%E4%B8%80%E5%8F%B0%E5%AE%8C%E7%BE%8E%E6%B5%8B%E8%AF%95%E6%9C%BA/" class="article-date">
  <time datetime="2020-11-10T03:51:38.000Z" itemprop="datePublished">2020-11-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/10/%E5%A6%82%E4%BD%95%E8%B0%83%E6%95%99%E4%B8%80%E5%8F%B0%E5%AE%8C%E7%BE%8E%E6%B5%8B%E8%AF%95%E6%9C%BA/">如何调教一台完美的测试机:AOSP刷入GMS记录</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近做开发时很多体验需要完整的gms服务框架，官方镜像可以体验，但是官方是release系统。aosp正常编译是不带gms的，而且webview的开发经常需要和系统webview作对比，因此需要一个能任意替换系统webview的userdebug系统并且带上gms。<br>需求如下：</p>
<ol>
<li>userdebug系统</li>
<li>支持随意替换系统webview</li>
<li>支持adb root，可以查看所有进程，跑chromium测试</li>
<li>刷入gms，带google服务框架，体验完整原生安卓</li>
</ol>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>最简单的方法是，使用第三方rom（最好修改较小，接近原生），例如魔趣、lineageOS、Omni等热门第三方rom，在recovery中依次刷入rom和opengapps的包即可。<br>不过我这次用的pixel4 其他第三方系统都不支持，只有lineageOS可以刷，但是刷入之后发现虽然是userdebug的系统，但是却换不了系统webview，怀疑他的编译选项有问题。<br>因此选择了下面的方法，自己编译aosp，编译时打入opengapps。</p>
<hr>
<h2 id="正文开始。-pixel-4-编译aosp-opengapps-，步骤-踩坑汇总："><a href="#正文开始。-pixel-4-编译aosp-opengapps-，步骤-踩坑汇总：" class="headerlink" title="正文开始。 pixel 4 编译aosp+opengapps ，步骤+踩坑汇总："></a>正文开始。 pixel 4 编译aosp+opengapps ，步骤+踩坑汇总：</h2><ol>
<li><p>拉取android 对应分支源码<br>例如pixel4</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">repo init -u https:&#x2F;&#x2F;android.googlesource.com&#x2F;platform&#x2F;manifest -b android-10.0.0_r41</span><br></pre></td></tr></table></figure></li>
<li><p>下载厂商驱动</p>
</li>
<li><p>例如pixel4 下载<a target="_blank" rel="noopener" href="https://developers.google.com/android/drivers#flameqq3a.200805.001">https://developers.google.com/android/drivers#flameqq3a.200805.001</a></p>
</li>
<li><p>解压后在源码目录下执行对应脚本，中间需要输入I ACCEPT</p>
</li>
<li><p>拉取opengapps 源码 <a target="_blank" rel="noopener" href="https://github.com/opengapps/aosp_build">https://github.com/opengapps/aosp_build</a></p>
</li>
<li><p>参照opengapps说明操作，其中最后一步拉代码 repo forall -c git lfs pull 非常容易失败要多来几次，失败的话编译会出错</p>
</li>
<li><p>小tips 建议选择小包，很多Google全家桶apk可以在playstore下载，而且有些和aosp兼容有问题，比如pixel4刷stock包刷完全屏手势失灵，刷nano/super包正常。</p>
</li>
<li><p>non-stock 包想要能自己随意替换系统webview的话需要开启GAPPS_FORCE_WEBVIEW_OVERRIDES := true</p>
</li>
<li><p>实际就是在配置 frameworks/base/core/res/res/xml/config_webview_packages.xml 这个文件</p>
</li>
<li><p>修改一处代码，否则pixellauncher起不来， 参考 <a target="_blank" rel="noopener" href="https://c55jeremy-tech.blogspot.com/2019/04/aosppixel-2-romrom.html">https://c55jeremy-tech.blogspot.com/2019/04/aosppixel-2-romrom.html</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--- a&#x2F;services&#x2F;core&#x2F;java&#x2F;com&#x2F;android&#x2F;server&#x2F;wm&#x2F;WindowManagerService.java</span><br><span class="line">+++ b&#x2F;services&#x2F;core&#x2F;java&#x2F;com&#x2F;android&#x2F;server&#x2F;wm&#x2F;WindowManagerService.java</span><br><span class="line">@@ -6001,8 +6001,8 @@ public class WindowManagerService extends IWindowManager.Stub</span><br><span class="line"></span><br><span class="line">     @Override</span><br><span class="line">     public void setShelfHeight(boolean visible, int shelfHeight) &#123;</span><br><span class="line">-        mAmInternal.enforceCallerIsRecentsOrHasPermission(android.Manifest.permission.STATUS_BAR,</span><br><span class="line">-                &quot;setShelfHeight()&quot;);</span><br><span class="line">+        &#x2F;&#x2F;mAmInternal.enforceCallerIsRecentsOrHasPermission(android.Manifest.permission.STATUS_BAR,</span><br><span class="line">+        &#x2F;&#x2F;        &quot;setShelfHeight()&quot;);</span><br><span class="line">         synchronized (mWindowMap) &#123;</span><br><span class="line">             getDefaultDisplayContentLocked().getPinnedStackController().setAdjustedForShelf(visible,</span><br><span class="line">                     shelfHeight)</span><br></pre></td></tr></table></figure></li>
<li><p>常规编译源码<br>lunch aosp_flame-userdebug<br>make -j8<br>如果这步编译有错误，就是上面repo拉apk没拉全，要删了对应目录重来</p>
</li>
<li><p>刷入 fastboot flashall -w</p>
</li>
<li><p>启动之后报设备未获得play保护机制认证，在<a target="_blank" rel="noopener" href="https://www.google.com/android/uncertified/">https://www.google.com/android/uncertified/</a> 注册设备的id，注册之后过一会就能正常用了。获取设备id的方法 :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">adb root</span><br><span class="line">adb shell</span><br><span class="line">sqlite3 &#x2F;data&#x2F;data&#x2F;com.google.android.gsf&#x2F;databases&#x2F;gservices.db  &#39;select * from main where name &#x3D; &quot;android_id&quot;;&#39;</span><br></pre></td></tr></table></figure></li>
<li><p>android 10.0 开启手势</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adb shell cmd overlay enable com.android.internal.systemui.navbar.gestural</span><br></pre></td></tr></table></figure>
</li>
<li><p>系统webview 替换姿势</p>
</li>
<li><p> 卸载系统webview 用chromium下脚本 android_webview/tools/remove_preinstalled_webview.py</p>
</li>
<li><p>安装新webview adb install 即可</p>
</li>
<li><p>如果需要让gapps刷入之后可以安装自编译版本的webview，需要在xml配置文件中加上</p>
<pre><code>&lt;webviewprovider description=&quot;Android WebView&quot; packageName=&quot;com.android.webview&quot; availableByDefault=&quot;true&quot;&gt;
&lt;/webviewprovider&gt;</code></pre>
</li>
<li><p>参考文档<a target="_blank" rel="noopener" href="https://chromium.googlesource.com/chromium/src/+/HEAD/android_webview/docs/aosp-system-integration.md">https://chromium.googlesource.com/chromium/src/+/HEAD/android_webview/docs/aosp-system-integration.md</a></p>
</li>
<li><p>验证结果</p>
</li>
<li><p>使用系统webview 访问 <a target="_blank" rel="noopener" href="https://wutong-apk.cdn.bcebos.com/%EF%BC%8C%E5%87%BA%E7%8E%B0%E7%BA%A2%E8%89%B2%E9%A3%8E%E9%99%A9%E6%8F%90%E7%A4%BA%E9%A1%B5%E9%9D%A2%EF%BC%8C%E8%AF%81%E6%98%8E%E7%B3%BB%E7%BB%9Fwbeview+gms%E5%B7%A5%E4%BD%9C%E6%AD%A3%E5%B8%B8%E3%80%82">https://wutong-apk.cdn.bcebos.com/，出现红色风险提示页面，证明系统wbeview+gms工作正常。</a></p>
</li>
<li><p>安装chromium源码编译出的自编译包，在设置/开发者选项中，能同时看到：</p>
<ol>
<li>官方的系统webview包，com.google.android.webview可以在play store升级</li>
<li>自编译webview包，com.android.webview</li>
</ol>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://bathingsun.xyz/2020/11/10/%E5%A6%82%E4%BD%95%E8%B0%83%E6%95%99%E4%B8%80%E5%8F%B0%E5%AE%8C%E7%BE%8E%E6%B5%8B%E8%AF%95%E6%9C%BA/" data-id="ckhlm4zd500003ms34zhs6qre" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-规则匹配引擎" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/16/%E8%A7%84%E5%88%99%E5%8C%B9%E9%85%8D%E5%BC%95%E6%93%8E/" class="article-date">
  <time datetime="2020-10-16T05:31:56.000Z" itemprop="datePublished">2020-10-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/16/%E8%A7%84%E5%88%99%E5%8C%B9%E9%85%8D%E5%BC%95%E6%93%8E/">规则匹配引擎</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="备选本地过滤引擎"><a href="#备选本地过滤引擎" class="headerlink" title="备选本地过滤引擎"></a>备选本地过滤引擎</h2><h3 id="AdBlock"><a href="#AdBlock" class="headerlink" title="AdBlock"></a>AdBlock</h3><p>AdBlock 目前主流支持easylist规则，基本格式是 filter$options 这种语法。<br>规则匹配引擎，要解决的问题主要是在海量规则中判断是否命中的问题。如果用正则或者遍历，消耗过大，一般采取的都是先把规则依据某种判据先分成小类别，匹配时先找到对应的小类别，然后在小类别中遍历规则完成匹配。<br>下面从分类方法、存储方法、匹配方法简述几种匹配引擎的实现。</p>
<h3 id="Brave-AdBlock-c-实现"><a href="#Brave-AdBlock-c-实现" class="headerlink" title="Brave AdBlock c++ 实现"></a>Brave AdBlock c++ 实现</h3><p>Brave AdBlock c++ 使用的分类方法是：</p>
<ul>
<li>计算阶段，用规则的filter部分，去掉特殊字符之后, 用指定长度算出一个key，插入到布隆过滤器中,插入前会先过一个坏key的大表（坏key可以认为是人工过了线上的top站点得出的冲突率最高的key）<ul>
<li>如果不是坏key则插入布隆过滤器，如果是坏key，则插入人工分类的几个集合中(例如根据规则是否限制域名，是否限制域名取反等特性分类），并通过hashset查询，hashset中使用规则的host或者filter部分计算key</li>
</ul>
</li>
<li>匹配阶段，先计算目标url所在的domain是否存在于几个hashset中，如果存在则在对应的规则集合中遍历；如果都不存在，则通过url算出所有可能的key，例如固定长度是7，就用url中的连续字符每7个字符算一个key，在布隆过滤器中匹配，如果不命中，则说明命中不了规则，如果命中则在剩余规则中遍历。</li>
<li>规则的序列化和反序列化使用brave实现的格式，加载时需要简单解析一下内容，然后用指针指向对应内存，反序列化文件mmap之后不能释放。<h3 id="Brave-Adblock-Rust实现"><a href="#Brave-Adblock-Rust实现" class="headerlink" title="Brave Adblock Rust实现"></a>Brave Adblock Rust实现</h3></li>
<li>计算阶段，首先规则的filter 部分，用规则包含的特殊字符（除了子母和数字之外的字符)将规则切分成多个token，这里需要注意的是，如果一个规则中间有通配符，则包含通配符的部分不能作为token，如<a target="_blank" rel="noopener" href="http://www.ba*du.com,计算出来的token是/">www.ba*du.com，计算出来的token是</a> {www,com}，ba和du因为包含通配符，如果作为token，在这个引擎的实现中，匹配时是无法处理的。<ul>
<li>准备将token作为当前规则的索引插入hashmap中，首先计算现存所有规则的token对应的map中，当前规则的token中出现次数最少的那个token，即最能独立代表当前规则的token，然后用这个token作为当前规则的key，插入hashmap</li>
</ul>
</li>
<li>匹配阶段，用上文计算过程中相同的分割规则，将目标url切分成对等的token，找到对应规则所在的所有小集合，遍历集合中的规则进行过滤。</li>
<li>存储，还没看<h3 id="Chromium-Subresource-Filter实现"><a href="#Chromium-Subresource-Filter实现" class="headerlink" title="Chromium Subresource Filter实现"></a>Chromium Subresource Filter实现</h3>Subresource Filter是chromium 7x版本开始自己实现的规则引擎，目前还在测试阶段未正式上线，可以为浏览器插件提供支持easylist语法的引擎（官方逼死同人系列）。</li>
<li>计算阶段，处理规则的filter，chromium的实现是把规则中除了通配符(<em>)和分隔符（^)之外的字符，用固定长度计算key，如果不到固定长度则忽略。例如 <a target="_blank" rel="noopener" href="http://www.ba/">www.ba</a></em>du.com 这个规则中，用chromium的方法计算key用的原始字符（假设长度是5)，就是{<a target="_blank" rel="noopener" href="http://www.b/">www.b</a> , ww.ba, du.co, u.com},这种集合<ul>
<li>计算key之后，插入hashmap时，寻找所有的key中，桶中元素最少的，类似brave的rust实现</li>
</ul>
</li>
<li>匹配阶段，首先对url也用固定长度算key，能算出很多个，然后每个key在hashmap中寻找对应规则所在的集合，遍历集合中的规则进行过滤。</li>
<li>存储阶段，chromium使用了自家的FlatBuffer，可以不经过反序列化，mmap之后直接使用，效率极高。</li>
</ul>
<p>看起来brave c++的实现在三者中最差，chromium的有可能略好于brave rust的实现，因为可以在算key时利用上规则里，通配符两边的字符，感觉上找到规则的准确率会提高。</p>
<h3 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h3><p>过滤引擎性能对比测试结论，brave rust略优于chromium实现，都远好于brave c++实现。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://bathingsun.xyz/2020/10/16/%E8%A7%84%E5%88%99%E5%8C%B9%E9%85%8D%E5%BC%95%E6%93%8E/" data-id="ckhk4587u0000kks348345zr0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Android-WebView-DrawFn-相关" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/09/22/Android-WebView-DrawFn-%E7%9B%B8%E5%85%B3/" class="article-date">
  <time datetime="2020-09-22T05:05:17.000Z" itemprop="datePublished">2020-09-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/22/Android-WebView-DrawFn-%E7%9B%B8%E5%85%B3/">Android WebView DrawFn 相关</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在 chromium 的较高版本 webview 中，适配了android Q 的 vulkan 渲染。<br>在 webview 的历史实现中，由于和 chrome 架构差异，需要使用 DrawGL 相关方法在 android view 中绘制内容。</p>
<p>chrome 浏览器是完全独立的app，因此完全实现了自己的渲染，没有用android的 view 框架；webview 由于要作为一个 view 嵌入 app，所以必须依托于 android 的 view 对象，webview 通过反射调用 android.view.DisplayListCanvas 的 drawGLFunctor 方法实现绘制。<br>在最新的代码中，为了使用 android Q 的 vulkan 框架，webview 使用了新的实现方法用于调用vulkan。</p>
<h2 id="plat-support"><a href="#plat-support" class="headerlink" title="plat_support"></a>plat_support</h2><p>plat_support 是个webview依赖的系统库，实现了webview的创建functor的方法，由于是平台相关，所以实在framework中提供。<br><a target="_blank" rel="noopener" href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/native/webview/plat_support/">https://cs.android.com/android/platform/superproject/+/master:frameworks/base/native/webview/plat_support/</a><br>在plat_support创建时会向一个webview的类中注册几个native方法，webview通过使用这些方法，创建系统版本对应的functor，如创建DrawGLFunctor的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const char kClassName[] &#x3D; &quot;com&#x2F;android&#x2F;webview&#x2F;chromium&#x2F;DrawGLFunctor&quot;;</span><br><span class="line">const JNINativeMethod kJniMethods[] &#x3D; &#123;</span><br><span class="line">    &#123; &quot;nativeCreateGLFunctor&quot;, &quot;(J)J&quot;,</span><br><span class="line">        reinterpret_cast&lt;void*&gt;(CreateGLFunctor) &#125;,</span><br><span class="line">    &#123; &quot;nativeDestroyGLFunctor&quot;, &quot;(J)V&quot;,</span><br><span class="line">        reinterpret_cast&lt;void*&gt;(DestroyGLFunctor) &#125;,</span><br><span class="line">    &#123; &quot;nativeSetChromiumAwDrawGLFunction&quot;, &quot;(J)V&quot;,</span><br><span class="line">        reinterpret_cast&lt;void*&gt;(SetChromiumAwDrawGLFunction) &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>以及创建能使用vulkan的DrawFunctor的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">char kClassName[]</span><br><span class="line">const JNINativeMethod kJniMethods[] &#x3D; &#123;</span><br><span class="line">    &#123;&quot;nativeGetFunctionTable&quot;, &quot;()J&quot;,</span><br><span class="line">     reinterpret_cast&lt;void*&gt;(GetDrawFnFunctionTable)&#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在创建DrawFunctor的table中，看指向create_functor的函数指针，指向了真正的创建函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">int CreateFunctor(void* data, AwDrawFnFunctorCallbacks* functor_callbacks) &#123;</span><br><span class="line">  static bool callbacks_initialized &#x3D; false;</span><br><span class="line">  static uirenderer::WebViewFunctorCallbacks webview_functor_callbacks &#x3D; &#123;</span><br><span class="line">      .onSync &#x3D; &amp;onSync,</span><br><span class="line">      .onContextDestroyed &#x3D; &amp;onContextDestroyed,</span><br><span class="line">      .onDestroyed &#x3D; &amp;onDestroyed,</span><br><span class="line">  &#125;;</span><br><span class="line">  if (!callbacks_initialized) &#123;</span><br><span class="line">    switch (uirenderer::WebViewFunctor_queryPlatformRenderMode()) &#123;</span><br><span class="line">      case uirenderer::RenderMode::OpenGL_ES:</span><br><span class="line">        webview_functor_callbacks.gles.draw &#x3D; &amp;draw_gl;</span><br><span class="line">        break;</span><br><span class="line">      case uirenderer::RenderMode::Vulkan:</span><br><span class="line">        webview_functor_callbacks.vk.initialize &#x3D; &amp;initializeVk;</span><br><span class="line">        webview_functor_callbacks.vk.draw &#x3D; &amp;drawVk;</span><br><span class="line">        webview_functor_callbacks.vk.postDraw &#x3D; &amp;postDrawVk;</span><br><span class="line">        break;</span><br><span class="line">    &#125;</span><br><span class="line">    callbacks_initialized &#x3D; true;</span><br><span class="line">  &#125;</span><br><span class="line">  SupportData* support &#x3D; new SupportData&#123;</span><br><span class="line">      .data &#x3D; data,</span><br><span class="line">      .callbacks &#x3D; *functor_callbacks,</span><br><span class="line">  &#125;;</span><br><span class="line">  int functor &#x3D; uirenderer::WebViewFunctor_create(</span><br><span class="line">      support, webview_functor_callbacks,</span><br><span class="line">      uirenderer::WebViewFunctor_queryPlatformRenderMode());</span><br><span class="line">  if (functor &lt;&#x3D; 0) delete support;</span><br><span class="line">  return functor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首次初始化时会根据平台相关特性，选择使用opengl还是vulkan。</p>
<h2 id="WebView-调用DrawGLFunctor过程"><a href="#WebView-调用DrawGLFunctor过程" class="headerlink" title="WebView 调用DrawGLFunctor过程"></a>WebView 调用DrawGLFunctor过程</h2><p>这部分网上分析很多，不详细记录了，大概就是AwContents.onDraw的时候反射调用canvas里一个私有的方法。webview 通过周期地触发InProcessCommandBuffer::Flush方法，触发renderThread的合成。</p>
<p>需要注意的是，chrome和 webview 在渲染上最大的区别就是，command buffer service线程，在chrome上生产者和消费者都在同一个service线程，在webview上，生产者和消费者在不同的线程，因为webview的渲染不是chromium自己管理的，他只输出EGLImage，交给android系统的RenderThread处理 ConsumeTexture。于是，webview使用MailboxManagerSync，而chrome使用MailboxManagerImpl，webview使用的是加锁多线程共享的方式实现。<br>附生产和消费texture的调用栈：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">(gdb) bt</span><br><span class="line">#0  gpu::gles2::MailboxManagerSync::ConsumeTexture () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;mailbox_manager_sync.cc:194</span><br><span class="line">#1  0xcbaa0f80 in gpu::gles2::GLES2DecoderImpl::DoCreateAndConsumeTextureINTERNAL () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;gles2_cmd_decoder.cc:18454</span><br><span class="line">#2  0xcba85898 in gpu::gles2::GLES2DecoderImpl::HandleCreateAndConsumeTextureINTERNALImmediate () at ..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;gles2_cmd_decoder_autogen.h:4946</span><br><span class="line">#3  0xcba8f6a0 in gpu::gles2::GLES2DecoderImpl::DoCommandsImpl&lt;false&gt; () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;gles2_cmd_decoder.cc:5932</span><br><span class="line">#4  0xcb9bdc54 in gpu::CommandBufferService::Flush () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;command_buffer_service.cc:69</span><br><span class="line">#5  0xcbb2163a in gpu::InProcessCommandBuffer::FlushOnGpuThread () at ..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;in_process_command_buffer.cc:913</span><br><span class="line">#6  0xca515508 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#7  0xca52ffde in base::internal::FunctorTraits&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), void&gt;::Invoke&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;(void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;&amp;&amp;, base::OnceCallback&lt;void ()&gt;&amp;&amp;) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:499</span><br><span class="line">#8  base::internal::InvokeHelper&lt;true, void&gt;::MakeItSo&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;(void (android_webview::AwCookieStoreWrapper::*&amp;&amp;)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;&amp;&amp;, base::OnceCallback&lt;void ()&gt;&amp;&amp;) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:619</span><br><span class="line">#9  base::internal::Invoker&lt;base::internal::BindState&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;, void ()&gt;::RunImpl&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), std::__1::tuple&lt;base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;, 0u, 1u&gt;(void (android_webview::AwCookieStoreWrapper::*&amp;&amp;)(base::OnceCallback&lt;void ()&gt;), std::__1::tuple&lt;base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;&amp;&amp;, std::__1::integer_sequence&lt;unsigned int, 0u, 1u&gt;) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:672</span><br><span class="line">#10 base::internal::Invoker&lt;base::internal::BindState&lt;void (android_webview::AwCookieStoreWrapper::*)(base::OnceCallback&lt;void ()&gt;), base::WeakPtr&lt;android_webview::AwCookieStoreWrapper&gt;, base::OnceCallback&lt;void ()&gt; &gt;, void ()&gt;::RunOnce(base::internal::BindStateBase*) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:641</span><br><span class="line">#11 0xca515508 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#12 0xca5484bc in android_webview::TaskForwardingSequence::RunTask(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;deferred_gpu_command_service.cc:108</span><br><span class="line">#13 0xca548544 in base::internal::FunctorTraits&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), void&gt;::Invoke&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;(void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;&amp;&amp;, base::OnceCallback&lt;void ()&gt;&amp;&amp;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;&amp;&amp;, unsigned int&amp;&amp;) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:499</span><br><span class="line">#14 base::internal::InvokeHelper&lt;true, void&gt;::MakeItSo&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;(void (android_webview::TaskForwardingSequence::*&amp;&amp;)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;&amp;&amp;, base::OnceCallback&lt;void ()&gt;&amp;&amp;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;&amp;&amp;, unsigned int&amp;&amp;) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:619</span><br><span class="line">#15 base::internal::Invoker&lt;base::internal::BindState&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;, void ()&gt;::RunImpl&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), std::__1::tuple&lt;base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;, 0u, 1u, 2u, 3u&gt;(void (android_webview::TaskForwardingSequence::*&amp;&amp;)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), std::__1::tuple&lt;base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;&amp;&amp;, std::__1::integer_sequence&lt;unsigned int, 0u, 1u, 2u, 3u&gt;) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:672</span><br><span class="line">#16 base::internal::Invoker&lt;base::internal::BindState&lt;void (android_webview::TaskForwardingSequence::*)(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int), base::WeakPtr&lt;android_webview::TaskForwardingSequence&gt;, base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;, unsigned int&gt;, void ()&gt;::RunOnce(base::internal::BindStateBase*) () at ..&#x2F;..&#x2F;base&#x2F;bind_internal.h:641</span><br><span class="line">#17 0xca515508 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#18 0xca547f16 in android_webview::DeferredGpuCommandService::RunTasks () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;deferred_gpu_command_service.cc:243</span><br><span class="line">#19 0xca547ec8 in android_webview::DeferredGpuCommandService::ScheduleTask(base::OnceCallback&lt;void ()&gt;, bool) () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;deferred_gpu_command_service.cc:188</span><br><span class="line">#20 0xca5483ac in android_webview::TaskForwardingSequence::ScheduleTask(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;deferred_gpu_command_service.cc:77</span><br><span class="line">#21 0xcbb2156e in gpu::InProcessCommandBuffer::ScheduleGpuTask(base::OnceCallback&lt;void ()&gt;, std::__1::vector&lt;gpu::SyncToken, std::__1::allocator&lt;gpu::SyncToken&gt; &gt;) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;in_process_command_buffer.cc:849</span><br><span class="line">#22 0xcbb219a6 in gpu::InProcessCommandBuffer::Flush () at ..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;in_process_command_buffer.cc:977</span><br><span class="line">#23 0xca7a9b84 in gpu::CommandBufferHelper::Flush () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;client&#x2F;cmd_buffer_helper.cc:182</span><br><span class="line">#24 0xcb8b2800 in gpu::gles2::GLES2Implementation::FlushHelper () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;client&#x2F;gles2_implementation.cc:1388</span><br><span class="line">#25 0xcb8b2a7c in gpu::gles2::GLES2Implementation::IssueShallowFlush () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;client&#x2F;gles2_implementation.cc:1378</span><br><span class="line">#26 0xca549968 in android_webview::ParentOutputSurface::SwapBuffers () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;parent_output_surface.cc:52</span><br><span class="line">#27 0xcba317dc in viz::GLRenderer::SwapBuffers () at .&#x2F;..&#x2F;..&#x2F;components&#x2F;viz&#x2F;service&#x2F;display&#x2F;gl_renderer.cc:2901</span><br><span class="line">#28 0xcba25d3a in viz::Display::DrawAndSwap () at .&#x2F;..&#x2F;..&#x2F;components&#x2F;viz&#x2F;service&#x2F;display&#x2F;display.cc:523</span><br><span class="line">#29 0xca54bba6 in android_webview::SurfacesInstance::DrawAndSwap () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;surfaces_instance.cc:239</span><br><span class="line">#30 0xca548fc8 in android_webview::HardwareRenderer::Draw () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;hardware_renderer.cc:182</span><br><span class="line">#31 0xca54a00c in android_webview::RenderThreadManager::DrawOnRT () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;render_thread_manager.cc:195</span><br><span class="line">#32 0xca544be2 in android_webview::AwGLFunctor::DrawGL () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;aw_gl_functor.cc:119</span><br><span class="line">---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---</span><br><span class="line">#33 DrawGLFunction () at ..&#x2F;..&#x2F;android_webview&#x2F;browser&#x2F;gfx&#x2F;aw_gl_functor.cc:27</span><br><span class="line">#34 0xec21d328 in android::(anonymous namespace)::DrawGLFunctor::operator()(int, void*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libwebviewchromium_plat_support.so</span><br><span class="line">#35 0xf26fc6de in android::uirenderer::skiapipeline::GLFunctorDrawable::onDraw(SkCanvas*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#36 0xf29b84b6 in SkDrawable::draw(SkCanvas*, SkMatrix const*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#37 0xf29b8ac2 in SkLiteDL::draw(SkCanvas*) const () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#38 0xf29a07e0 in android::uirenderer::skiapipeline::RenderNodeDrawable::drawContent(SkCanvas*) const () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#39 0xf29a0af6 in android::uirenderer::skiapipeline::RenderNodeDrawable::forceDraw(SkCanvas*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#40 0xf2703d3e in android::uirenderer::skiapipeline::SkiaPipeline::renderLayersImpl(android::uirenderer::LayerUpdateQueue const&amp;, bool, bool) ()</span><br><span class="line">   from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#41 0xf29d3d1a in android::uirenderer::skiapipeline::SkiaPipeline::renderFrame(android::uirenderer::LayerUpdateQueue const&amp;, SkRect const&amp;, std::__1::vector&lt;android::sp&lt;android::uirenderer::RenderNode&gt;, std::__1::allocator&lt;android::sp&lt;android::uirenderer::RenderNode&gt; &gt; &gt; const&amp;, bool, bool, android::uirenderer::Rect const&amp;, sk_sp&lt;SkSurface&gt;) ()</span><br><span class="line">   from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#42 0xf29d33de in android::uirenderer::skiapipeline::SkiaOpenGLPipeline::draw(android::uirenderer::renderthread::Frame const&amp;, SkRect const&amp;, SkRect const&amp;, android::uirenderer::FrameBuilder::LightGeometry const&amp;, android::uirenderer::LayerUpdateQueue*, android::uirenderer::Rect const&amp;, bool, bool, android::uirenderer::BakedOpRenderer::LightInfo const&amp;, std::__1::vector&lt;android::sp&lt;android::uirenderer::RenderNode&gt;, std::__1::allocator&lt;android::sp&lt;android::uirenderer::RenderNode&gt; &gt; &gt; const&amp;, android::uirenderer::FrameInfoVisualizer*) ()</span><br><span class="line">   from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#43 0xf270c42c in android::uirenderer::renderthread::CanvasContext::draw() () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#44 0xf29d6b08 in std::__1::__function::__func&lt;android::uirenderer::renderthread::DrawFrameTask::postAndWait()::$_0, std::__1::allocator&lt;android::uirenderer::renderthread::DrawFrameTask::postAndWait()::$_0&gt;, void ()&gt;::operator() () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#45 0xf299fb30 in android::uirenderer::WorkQueue::process() () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#46 0xf271519e in android::uirenderer::renderthread::RenderThread::threadLoop() () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libhwui.so</span><br><span class="line">#47 0xf132f088 in android::Thread::_threadLoop(void*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libutils.so</span><br><span class="line">#48 0xf1ea940a in __pthread_start(void*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libc.so</span><br><span class="line">#49 0xf1e630ce in __start_thread () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libc.so</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">(gdb) bt</span><br><span class="line">#0  gpu::gles2::MailboxManagerSync::ProduceTexture () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;mailbox_manager_sync.cc:226</span><br><span class="line">#1  0xcbae0318 in gpu::SharedImageBackingPassthroughGLTexture::ProduceLegacyMailbox ()</span><br><span class="line">    at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_backing_factory_gl_texture.cc:593</span><br><span class="line">#2  0xcbad10b6 in gpu::SharedImageRepresentationFactoryRef::ProduceLegacyMailbox () at ..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_representation.h:73</span><br><span class="line">#3  gpu::SharedImageFactory::RegisterBacking () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_factory.cc:287</span><br><span class="line">#4  0xcbad0f96 in gpu::SharedImageFactory::CreateSharedImage () at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_factory.cc:117</span><br><span class="line">#5  0xcbb2bdf4 in gpu::SharedImageStub::OnCreateSharedImage () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;shared_image_stub.cc:99</span><br><span class="line">#6  0xcbb2baf4 in base::DispatchToMethodImpl&lt;gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;, 0u&gt;(gpu::SharedImageStub* const&amp;, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;, std::__1::integer_sequence&lt;unsigned int, 0u&gt;) () at ..&#x2F;..&#x2F;base&#x2F;tuple.h:52</span><br><span class="line">#7  base::DispatchToMethod&lt;gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt; &gt;(gpu::SharedImageStub* const&amp;, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;) () at ..&#x2F;..&#x2F;base&#x2F;tuple.h:60</span><br><span class="line">#8  IPC::DispatchToMethod&lt;gpu::SharedImageStub, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), void, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt; &gt;(gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), void*, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;ipc&#x2F;ipc_message_templates.h:51</span><br><span class="line">#9  IPC::MessageT&lt;GpuChannelMsg_CreateSharedImage_Meta, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;, void&gt;::Dispatch&lt;gpu::SharedImageStub, gpu::SharedImageStub, void, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;)&gt; () at ..&#x2F;..&#x2F;ipc&#x2F;ipc_message_templates.h:146</span><br><span class="line">#10 gpu::SharedImageStub::OnMessageReceived () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;shared_image_stub.cc:69</span><br><span class="line">#11 0xcbb280b8 in gpu::GpuChannel::HandleMessageHelper () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;gpu_channel.cc:597</span><br><span class="line">#12 0xcbb273b0 in gpu::GpuChannel::HandleMessage () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;gpu_channel.cc:560</span><br><span class="line">#13 0xcb9bf9b6 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#14 gpu::Scheduler::RunNextTask () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;scheduler.cc:527</span><br><span class="line">#15 0xcb1088c8 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#16 base::TaskAnnotator::RunTask () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;common&#x2F;task_annotator.cc:114</span><br><span class="line">#17 base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::DoWorkImpl () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;sequence_manager&#x2F;thread_controller_with_message_pump_impl.cc:363</span><br><span class="line">#18 0xcb10855c in base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::DoSomeWork () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;sequence_manager&#x2F;thread_controller_with_message_pump_impl.cc:214</span><br><span class="line">#19 0xcb108d9c in non-virtual thunk to base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::DoSomeWork() () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;time&#x2F;time_now_posix.cc:52</span><br><span class="line">#20 0xcb0e6e9c in base::MessagePumpDefault::Run () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;message_loop&#x2F;message_pump_default.cc:39</span><br><span class="line">#21 0xcb1090fe in base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::Run () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;sequence_manager&#x2F;thread_controller_with_message_pump_impl.cc:448</span><br><span class="line">#22 0xcb0f36de in base::RunLoop::RunWithTimeout () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;run_loop.cc:161</span><br><span class="line">#23 0xcb119ab2 in base::Thread::ThreadMain () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;threading&#x2F;thread.cc:312</span><br><span class="line">#24 0xcb13b010 in base::(anonymous namespace)::ThreadFunc () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;threading&#x2F;platform_thread_posix.cc:81</span><br><span class="line">#25 0xf1ea940a in __pthread_start(void*) () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libc.so</span><br><span class="line">#26 0xf1e630ce in __start_thread () from &#x2F;tmp&#x2F;adb-gdb-libs-803fd342&#x2F;system&#x2F;lib&#x2F;libc.so</span><br></pre></td></tr></table></figure>
<p>RasterTileWorker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#0  gpu::SharedImageInterfaceProxy::CreateSharedImage () at ..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;client&#x2F;shared_image_interface_proxy.cc:63</span><br><span class="line">#1  0xc2ae3952 in cc::(anonymous namespace)::RasterizeSourceOOP () at .&#x2F;..&#x2F;..&#x2F;cc&#x2F;raster&#x2F;gpu_raster_buffer_provider.cc:142</span><br><span class="line">#2  cc::GpuRasterBufferProvider::PlaybackOnWorkerThreadInternal () at .&#x2F;..&#x2F;..&#x2F;cc&#x2F;raster&#x2F;gpu_raster_buffer_provider.cc:546</span><br><span class="line">#3  cc::GpuRasterBufferProvider::PlaybackOnWorkerThread () at .&#x2F;..&#x2F;..&#x2F;cc&#x2F;raster&#x2F;gpu_raster_buffer_provider.cc:470</span><br><span class="line">#4  cc::GpuRasterBufferProvider::RasterBufferImpl::Playback () at .&#x2F;..&#x2F;..&#x2F;cc&#x2F;raster&#x2F;gpu_raster_buffer_provider.cc:325</span><br><span class="line">#5  0xc2b4b6c8 in cc::(anonymous namespace)::RasterTaskImpl::RunOnWorkerThread () at .&#x2F;..&#x2F;..&#x2F;cc&#x2F;tiles&#x2F;tile_manager.cc:160</span><br><span class="line">#6  0xc365e4d2 in content::CategorizedWorkerPool::RunTaskInCategoryWithLockAcquired () at .&#x2F;..&#x2F;..&#x2F;content&#x2F;renderer&#x2F;categorized_worker_pool.cc:400</span><br><span class="line">#7  content::CategorizedWorkerPool::RunTaskWithLockAcquired () at .&#x2F;..&#x2F;..&#x2F;content&#x2F;renderer&#x2F;categorized_worker_pool.cc:378</span><br><span class="line">#8  content::CategorizedWorkerPool::Run () at .&#x2F;..&#x2F;..&#x2F;content&#x2F;renderer&#x2F;categorized_worker_pool.cc:260</span><br><span class="line">#9  content::(anonymous namespace)::CategorizedWorkerPoolThread::Run () at .&#x2F;..&#x2F;..&#x2F;content&#x2F;renderer&#x2F;categorized_worker_pool.cc:55</span><br><span class="line">#10 0xc21896a6 in base::SimpleThread::ThreadMain () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;threading&#x2F;simple_thread.cc:80</span><br><span class="line">#11 0xc21ad234 in base::(anonymous namespace)::ThreadFunc () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;threading&#x2F;platform_thread_posix.cc:81</span><br></pre></td></tr></table></figure>
<p>InProcGPUThread</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#0  gpu::SharedImageBackingFactoryGLTexture::MakeBacking ()</span><br><span class="line">    at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_backing_factory_gl_texture.cc:1222</span><br><span class="line">#1  0xc2d72960 in gpu::SharedImageBackingFactoryGLTexture::CreateSharedImage ()</span><br><span class="line">    at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_backing_factory_gl_texture.cc:1052</span><br><span class="line">#2  0xc2d72442 in gpu::SharedImageBackingFactoryGLTexture::CreateSharedImage ()</span><br><span class="line">    at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_backing_factory_gl_texture.cc:857</span><br><span class="line">#3  0xc2d74fe6 in gpu::SharedImageFactory::CreateSharedImage ()</span><br><span class="line">    at ..&#x2F;..&#x2F;third_party&#x2F;mesa_headers&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;shared_image_factory.cc:115</span><br><span class="line">#4  0xc2dd1540 in gpu::SharedImageStub::OnCreateSharedImage () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;shared_image_stub.cc:99</span><br><span class="line">#5  0xc2dd1250 in base::DispatchToMethodImpl&lt;gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;, 0u&gt;(gpu::SharedImageStub* const&amp;, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;, std::__1::integer_sequence&lt;unsigned int, 0u&gt;) ()</span><br><span class="line">    at ..&#x2F;..&#x2F;base&#x2F;tuple.h:52</span><br><span class="line">#6  base::DispatchToMethod&lt;gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt; &gt;(gpu::SharedImageStub* const&amp;, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;) () at ..&#x2F;..&#x2F;base&#x2F;tuple.h:60</span><br><span class="line">#7  IPC::DispatchToMethod&lt;gpu::SharedImageStub, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), void, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt; &gt;(gpu::SharedImageStub*, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;), void*, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;&amp;&amp;) () at ..&#x2F;..&#x2F;ipc&#x2F;ipc_message_templates.h:51</span><br><span class="line">#8  IPC::MessageT&lt;GpuChannelMsg_CreateSharedImage_Meta, std::__1::tuple&lt;GpuChannelMsg_CreateSharedImage_Params&gt;, void&gt;::Dispatch&lt;gpu::SharedImageStub, gpu::SharedImageStub, void, void (gpu::SharedImageStub::*)(GpuChannelMsg_CreateSharedImage_Params const&amp;)&gt; ()</span><br><span class="line">    at ..&#x2F;..&#x2F;ipc&#x2F;ipc_message_templates.h:146</span><br><span class="line">#9  gpu::SharedImageStub::OnMessageReceived () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;shared_image_stub.cc:69</span><br><span class="line">#10 0xc2dcd8b0 in gpu::GpuChannel::HandleMessageHelper () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;gpu_channel.cc:614</span><br><span class="line">#11 0xc2dccbbc in gpu::GpuChannel::HandleMessage () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;ipc&#x2F;service&#x2F;gpu_channel.cc:570</span><br><span class="line">#12 0xc2c337ce in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#13 gpu::Scheduler::RunNextTask () at .&#x2F;..&#x2F;..&#x2F;gpu&#x2F;command_buffer&#x2F;service&#x2F;scheduler.cc:527</span><br><span class="line">#14 0xc2245d46 in base::OnceCallback&lt;void ()&gt;::Run() &amp;&amp; () at ..&#x2F;..&#x2F;base&#x2F;callback.h:97</span><br><span class="line">#15 base::TaskAnnotator::RunTask () at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;common&#x2F;task_annotator.cc:114</span><br><span class="line">#16 0xc22501f0 in base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::DoWorkImpl ()</span><br><span class="line">    at .&#x2F;..&#x2F;..&#x2F;base&#x2F;task&#x2F;sequence_manager&#x2F;thread_controller_with_message_pump_impl.cc:363</span><br><span class="line">#17 0xc224ff5a in base::sequence_manager::internal::ThreadControllerWithMessagePumpImpl::DoSomeWork ()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://bathingsun.xyz/2020/09/22/Android-WebView-DrawFn-%E7%9B%B8%E5%85%B3/" data-id="ckhk36rdh0000frs32afu3kfl" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Media-相关-Tips" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/01/Media-%E7%9B%B8%E5%85%B3-Tips/" class="article-date">
  <time datetime="2020-01-01T05:09:59.000Z" itemprop="datePublished">2020-01-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/01/Media-%E7%9B%B8%E5%85%B3-Tips/">Media 相关 Tips</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Fragment-MP4"><a href="#Fragment-MP4" class="headerlink" title="Fragment MP4"></a>Fragment MP4</h2><p>简称fmp4，一种特殊的MP4封装。<br>常规的mp4文件将metadata放在文件结尾，ffmpeg可以用 -movflags faststart将metadata放在开头以支持更好的播放。<br>分片的mp4会将每个片段的metadata和片段一起存放，并在头部有一个moov。<br>moov [moof mdat]+<br>在fmp4中，moov只保存基本信息，如track的数量，codec信息等。<br>Sample的位置和大小信息都保存在moof中。紧跟着moof的就是moof中记录了信息的sample块（mdat）。</p>
<p>MP4的一些box：<br>ftyp File Type Box<br>moov Movie Header Box<br>sidx Segment Index<br>moof movie fragment</p>
<p>分片的mp4结构：头部moov+sidx<br>每个分片moof+mdat</p>
<h2 id="MP4的交织、分段、分片"><a href="#MP4的交织、分段、分片" class="headerlink" title="MP4的交织、分段、分片"></a>MP4的交织、分段、分片</h2><p>以下操作基于MP4Box。</p>
<p>简单说：如果要支持边下边播，交织；如果需要流畅跳转，分段；如果需要自适应切换分辨率，分片。</p>
<p>Interleaving (-inter) is when (groups of ) samples of different tracks are stored alternatively in the file: e.g. N milliseconds of video samples, followed by N milliseconds of audio samples, followed by N milliseconds of video samples … Typically, interleaved samples are grouped within an interleaving window. Interleaving reduces disk accesses, playback buffer requirements and enables progressive download and playback.<br>交织（-inter）是指不同轨道的（一组）样本交替存储在文件中：例如<br>N毫秒的视频样本，接着是N毫秒的音频样本，接着是N毫秒的视频样本……通常，交错的样本在交错窗口内分组。<br>交错可减少磁盘访问，回放缓冲要求并支持渐进式下载和回放。</p>
<p>Fragmentation (-frag) is an optional process applicable to the MP4 file format. By default, MP4 files generated with MP4Box are not fragmented. This process consists in using Movie Fragments (moof). Movie Fragments is a tool introduced in the ISO spec to improve recording of long-running sequences and that is now used for HTTP streaming. Even if it is possible, according to the ISO spec, to do interleaving on fragments, MP4Box currently does not support it, because we don’t see important use cases for it. For instance, all audio samples within a fragment are contiguously stored and similarly for the video samples. The only way to ‘interleave’ tracks is to have small fragments. There may be some overhead for big files, we welcome comments on this.</p>
<p>分段（-frag）是适用于MP4文件格式的可选过程。<br>默认情况下，使用MP4Box生成的MP4文件不会碎片化。<br>此过程包括使用电影片段（moof）。<br>Movie Fragments是ISO规范中引入的工具，用于改进长时间运行序列的记录，现在用于HTTP流式传输。<br>即使有可能，根据ISO规范，对片段进行交错，MP4Box目前也不支持它，因为我们没有看到重要的用例。<br>例如，片段内的所有音频样本被连续存储，并且类似地用于视频样本。<br>“交错”轨道的唯一方法是使用小片段。<br>大文件可能有一些开销，我们欢迎对此发表评论。</p>
<p>Segmentation (-dash) is the process of creating segments, parts of an original file meant for individual/separate HTTP download (not necessarily for individual playback). A segment can be a part of a big file or a separate file. It is not specific to the MP4 file format (in particular it may apply to MPEG-2 TS) but a segment may imply specific ISO signaling (styp and sidx boxes, for instance). A segment is what is refered to by the XML file used to drive the HTTP Streaming and segment boundaries can be convenient places for bitstream switching. Segmentation often implies fragmentation but not necessarily.</p>
<p>分段（-dash）是创建段的过程，原始文件的一部分用于单独/单独的HTTP下载（不一定用于单独回放）。<br>段可以是大文件的一部分或单独的文件。<br>它不是特定于MP4文件格式（特别是它可以应用于MPEG-2TS），但是段可以暗示特定的ISO信令（例如styp和sidx框）。<br>段是用于驱动HTTP流的XML文件所指的段，段边界可以是用于比特流切换的便利位置。<br>细分通常意味着碎片，但不一定。</p>
<h2 id="DASH的构成"><a href="#DASH的构成" class="headerlink" title="DASH的构成"></a>DASH的构成</h2><p>Danymic Adaptive Streaming over HTTP。类似苹果的HLS。</p>
<p>MPD: an XML document describing where the various media resources present in the content are located. The media resources can be single-media (for example, a video-only MP4 file) or a multiplexed set of streams (for example an AV MPEG-2 Transort Stream). Streams can be scalable (such as SVC) but we won’t go into such details as GPAC doesn’t support advanced description of scalable streams in DASH. Some media resources may exist in different versions, for example different bitrate or language or resolutions. In DASH, such a “version” of the stream is called a representation, and all representations are grouped together in an AdaptationSet.<br>segment: a continuous part of a media resource. The segment is the smallest part of the media that can be located in the MPD. What a segment exactly contains depends on the underlying media format of the content.<br>subsegment: a continuous part of a segment, or of a subsegment.<br>sidx: short name for SegmentIndexBox, this is an ISOBMF (MP4/3GP container) structure describing a segment by giving its earliest presentation time, how the segment is further divided into subsegments, random access points locations (byte offset) and timing in the segment payload. The goal of the SIDX is to build an index of the segment at a given granularity to simplify trick modes (seeking, fast-forward, fast-rewind, …).<br>Google翻译：<br>MPD：描述内容中存在的各种媒体资源的位置的XML文档。<br>媒体资源可以是单媒体（例如，仅视频MP4文件）或多路复用的流集（例如AV MPEG-2 Transort流）。<br>流可以是可扩展的（例如SVC），但我们不会详细介绍GPAC不支持DASH中可伸缩流的高级描述。<br>某些媒体资源可能存在于不同版本中，例如不同的比特率或语言或分辨率。<br>在DASH中，流的这种“版本”被称为表示，并且所有表示在AdaptationSet中被组合在一起。<br>segment：媒体资源的连续部分。<br>该段是可以位于MPD中的媒体的最小部分。<br>段确切包含的内容取决于内容的基础媒体格式。<br>子段：段或子段的连续部分。<br>sidx：SegmentIndexBox的短名称，这是一个ISOBMF（MP4 / 3GP容器）结构，通过给出其最早的呈现时间，段如何进一步划分为子段，随机访问点位置（字节偏移）和段中的时序来描述段<br>有效载荷。<br>SIDX的目标是以给定的粒度构建段的索引，以简化特技模式（搜索，快进，快退，……）。</p>
<h2 id="MKV-MIME-type"><a href="#MKV-MIME-type" class="headerlink" title="MKV MIME type"></a>MKV MIME type</h2><p>Mkv没有官方的mime type，一般用video/x-matroska</p>
<p>获取服务器返回的http header中的mime type<br>Curl -I <a target="_blank" rel="noopener" href="http://xxx/">http://xxx</a></p>
<h2 id="流媒体协议"><a href="#流媒体协议" class="headerlink" title="流媒体协议"></a>流媒体协议</h2><p>RTMP 基于tcp的低延时协议，flash支持<br>HLS 基于http的协议，中高延时<br>DASH 类似HLS，中高延时<br>WebRTC 低延时协议，但是支持的设备有限</p>
<h2 id="YUV颜色模式"><a href="#YUV颜色模式" class="headerlink" title="YUV颜色模式"></a>YUV颜色模式</h2><p>YUV分为打包格式和平面格式。<br>Packed format vs. planar format<br>在打包格式中，YUV存储在一个序列中，在平面格式中，YUV被存储为三个单独的平面，平面格式需要多个纹理，每个平面需要一个纹理。</p>
<p>##　Linux进程获取本进程是否正在被debug<br>Chromium中 base::debug::WaitForDebugger(time, silent);<br>原理：<br>/proc/self/status中有一条记录： TracerPid: 0<br>被调试时有值。<br>1.可以用此方法让进程等待debug<br>while( ! isdebug() ) {<br>sleep(1);<br>}<br>isdebug中读取TracerPid的值看是否为0。</p>
<p>2.还有一种比较粗暴的方法<br>volitale int test=1;<br>while(test) {<br>sleep(1);<br>}<br>GDB attach之后，set var test=0</p>
<p>用这个方法可以在一些不方便打断点的地方（如浏览器启动时）等待gdb连接。</p>
<h2 id="视频码率控制"><a href="#视频码率控制" class="headerlink" title="视频码率控制"></a>视频码率控制</h2><p>CBR VBR<br>CBR constant bitrate 恒定比特率<br>VBR variable bitrate 可变比特率<br>VBV Video Buffering Verifier 视频缓冲区验证</p>
<p>几种控制模式：</p>
<p>Constant QP/CQP<br>QP quantization parameter 控制Mcroblock的质量，QP越高压缩率越高质量越差。<br>CQP会导致比特率根据场景复杂度变化很大，并且编码效率降低。一般只作为研究用。</p>
<p>Average Bitrate ABR<br>ffmpeg -i input -c:v libx264 -b:v 1M output<br>因为编码器无法准确知道未来的帧分布情况，因此只能估计，<br>ABR模式会导致质量波动严重，不建议使用.</p>
<p>Constant Bitrate<br>ffmpeg -i input -c:v libx264 -x264-params “nal-hrd=cbr:fore-cfr=1” -b:v 1M -minrate 1M -maxrate 1M -bufsize 2M output<br>ffmpeg -i input -c:v libvpx-vp9 -b:v 1M -maxrate 1M -minrate 1M output<br>固定比特率，使用libx264时需要输出格式为ts，因为mp4不支持NAL。<br>如果输入源易于编码，此模式会浪费带宽。</p>
<p>2-Pass ABR<br>编码器通过两次编码生成码流，第一次计算编码帧的编码成本，第二次更有效的使用bit，确保输出质量最佳。<br>x264<br>ffmpeg -i input -c:v libx264 -b:v 1M -pass 1 -f mp4 /dev/null<br>ffmpeg -i input -c:v libx264 -b:v 1M -pass 2 .mp4<br>x265<br>ffmpeg -i input -c:v libx264 -b:v 1M -x265-params pass=1 -f mp4 /dev/null<br>ffmpeg -i input -c:v libx264 -b:v 1M -x265-params pass=2 .mp4<br>vp9<br>ffmpeg -i input -c:v libvpx-vp9 -b:v 1M -pass 1 -f webm /dev/null<br>ffmpeg -i input -c:v libvpx-vp9 -b:v 1M -pass 2 .webm</p>
<p>Constant Quality (CQ) / Constant Rate Factor (CRF)<br>CRF是x264和x265的默认质量设置参数，可选值0-51，越小质量越好。<br>CRF模式在编码过程中保持恒定的质量，和2passABR相比，CRF模式只需设置质量，2passABR可以控制文件大小，<br>CRF在1pass编码中提供最佳的压缩率，但是无法限制文件大小和比特率，因此不建议流式传输使用。</p>
<p>ffmpeg -i input -c:v libx264 -crf 23<br>ffmpeg -i input -c:v libx265 -crf 28<br>ffmpeg -i input -c:v libvpx-vp9 -crf 30 -b:v 0</p>
<p>Constrained Encoding (VBV)<br>确保最大最小的比特率，可以和2passABR、CRF同时使用。<br>ffmpeg -i input -c:v libx264 -crf 23 -maxrate 1M -bufsize 2M<br>ffmpeg -i input -c:v libx265 -crf 28 -x265-params vbv-maxrate=1000:vbv-bufsize=2000<br>ffmpeg -i input -c:v libvpx-vp9 -crf 30 -b:v 2M</p>
<p>对于x264 x265，可以用-tune zerolatency和 -preset ultrafast提高编码速度，降低质量。<br>对于VP9，可以用-quality realtime和-speed 5。</p>
<p>2passABR+VBV<br>ffmpeg -i input -c:v libx264 -b:v 1M -maxrate 1M -bufsize 2M -pass 1 -f mp4 /dev/null<br>ffmpeg -i input -c:v libx264 -b:v 1M -maxrate 1M -bufsize 2M -pass 2<br>ffmpeg -i input -c:v libx265 -b:v 1M -x265-params pass=1:vbv-maxrate=1000:vbv-bufsize=2000 -f mp4 /dev/null<br>ffmpeg -i input -c:v libx265 -b:v 1M -x265-params pass=2:vbv-maxrate=1000:vbv-bufsize=2000</p>
<p>ffmpeg -i input -c:v libvpx-vp9 -b:v 1M -maxrate 1M -bufsize 2M -pass 1 -f webm /dev/null<br>ffmpeg -i input -c:v libvpx-vp9 -b:v 1M -maxrate 1M -bufsize 2M -pass 2</p>
<p>bufsize如果不确定，可以设置成maxrate的两倍大小。如果客户端内存很少，可以与maxrate相同。如果限制比特率，可以设置为maxrate的一半或更低。</p>
<p>总结，根据使用场景：<br>存档：CRF<br>流：2passCRF或ABR+VBV<br>直播：1passCRF或ABR+VBV<br>为设备编码：2passABR<br>Shaka player<br>Google的js播放器，支持MSE 、EME、DASH等播放格式。<br>不支持SegmentList中的SegmentURL@indexRange属性，<br>仅支持SegmentList@duration或SegmentTimeline</p>
<h2 id="ffmpeg添加分辨率水印（用于测试DASH自适应切换分辨率）"><a href="#ffmpeg添加分辨率水印（用于测试DASH自适应切换分辨率）" class="headerlink" title="ffmpeg添加分辨率水印（用于测试DASH自适应切换分辨率）"></a>ffmpeg添加分辨率水印（用于测试DASH自适应切换分辨率）</h2><p>ffmpeg -y -i frag_aac.flv -c:a libfdk_aac -ac 2 -ab 128k -c:v libx264 -x264opts ‘keyint=24:min-keyint=24:no-scenecut’ -b:v 800k -maxrate 800k -bufsize 500k -vf “scale=-1:540, drawtext=fontfile=/usr/share/fonts/truetype/msttcorefonts/arial.ttf: text=’540:%{frame_num}’: start_number=1: x=(w-tw)/2: y=h-(2*lh): fontcolor=black: fontsize=20: box=1: boxcolor=white: boxborderw=5” ./dash_800k.mp4</p>
<h2 id="检查关键帧位置"><a href="#检查关键帧位置" class="headerlink" title="检查关键帧位置"></a>检查关键帧位置</h2><p>两种方法：<br>ffprobe -loglevel error -skip_frame nokey -select_streams v:0 -show_entries frame=pkt_pts_time -of csv=print_section=0 frag_dash.mp4</p>
<p>ffprobe frag_dash.mp4 -show_frames -select_streams v:0 | grep key_frame</p>
<h2 id="检查关键帧对齐"><a href="#检查关键帧对齐" class="headerlink" title="检查关键帧对齐"></a>检查关键帧对齐</h2><p>Check key frame alignment<br><a target="_blank" rel="noopener" href="https://gpac.wp.imt.fr/2015/11/02/check-key-frame-alignment-with-mp4box/">https://gpac.wp.imt.fr/2015/11/02/check-key-frame-alignment-with-mp4box/</a></p>
<h2 id="平均GOP长度"><a href="#平均GOP长度" class="headerlink" title="平均GOP长度"></a>平均GOP长度</h2><p>Get average GOP length:<br>MP4Box -info TRACK_ID source1.mp4 2&gt;&amp;1 | grep GOP</p>
<p>MP4Box -std -diso source1.mp4 2&gt;&amp;1 | grep SyncSampleEntry &gt; 1.txt</p>
<h2 id="打印关键帧时间"><a href="#打印关键帧时间" class="headerlink" title="打印关键帧时间"></a>打印关键帧时间</h2><p>print key frame time:<br>ffprobe -loglevel error -skip_frame nokey -select_streams v:0 -show_entries frame=pkt_pts_time -of csv=print_section=0 input.mp4</p>
<p>如果MP4Box生成的video 和audio切片数量不同<br>Different number of segments for video and audio when use mp4box:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/gpac/gpac/issues/774">https://github.com/gpac/gpac/issues/774</a><br><a target="_blank" rel="noopener" href="https://github.com/gpac/gpac/issues/771">https://github.com/gpac/gpac/issues/771</a></p>
<h2 id="DASH-和-HLS"><a href="#DASH-和-HLS" class="headerlink" title="DASH 和 HLS"></a>DASH 和 HLS</h2><p>DASH 使用.mpd 文件索引，切片格式为fragment mp4<br>HLS使用.m3u8 文件索引，切片格式为ts</p>
<h2 id="ffmpeg和mp4box为dash格式转码"><a href="#ffmpeg和mp4box为dash格式转码" class="headerlink" title="ffmpeg和mp4box为dash格式转码"></a>ffmpeg和mp4box为dash格式转码</h2><p>ffmpeg encode for dash :<br>must has I-frames on same timestamp</p>
<h2 id="重新编码视频，在相同位置插入I帧："><a href="#重新编码视频，在相同位置插入I帧：" class="headerlink" title="重新编码视频，在相同位置插入I帧："></a>重新编码视频，在相同位置插入I帧：</h2><p>ffmpeg -y -i inputfile -c:a libfdk_aac -ac 2 -ab 128k -c:v libx264 -x264opts ‘keyint=24:min-keyint=24:no-scenecut’ -b:v 1500k -maxrate 1500k -bufsize 1000k -vf “scale=-1:720” outputfile720.mp4</p>
<p>ffmpeg -y -i inputfile -c:a libfdk_aac -ac 2 -ab 128k -c:v libx264 -x264opts ‘keyint=24:min-keyint=24:no-scenecut’ -b:v 800k -maxrate 800k -bufsize 500k -vf “scale=-1:540” outputfile540.mp4</p>
<p>ffmpeg -y -i inputfile -c:a libfdk_aac -ac 2 -ab 128k -c:v libx264 -x264opts ‘keyint=24:min-keyint=24:no-scenecut’ -b:v 400k -maxrate 400k -bufsize 400k -vf “scale=-1:360” outputfile360.mp4</p>
<p>keyint：GOP长度<br>min-keyint：最小GOP长度<br>Dash自适应切换清晰度要求不同分辨率的视频流必须在相同位置有关键帧。</p>
<h2 id="用MP4Box添加track："><a href="#用MP4Box添加track：" class="headerlink" title="用MP4Box添加track："></a>用MP4Box添加track：</h2><p>MP4Box -add outputfile720.mp4#video -fps 24 output.mp4</p>
<h2 id="用MP4Box制作dash："><a href="#用MP4Box制作dash：" class="headerlink" title="用MP4Box制作dash："></a>用MP4Box制作dash：</h2><p>MP4Box -dash 2000 -rap -bs-switching no output.mp4#trackID=1:dur=60 output.mp4#trackID=2:dur=60 output.mp4#trackID=3:dur=60 -out mpds/output_dash.mpd</p>
<h2 id="ffmpeg转码时设置GOP的参数"><a href="#ffmpeg转码时设置GOP的参数" class="headerlink" title="ffmpeg转码时设置GOP的参数"></a>ffmpeg转码时设置GOP的参数</h2><p>libx264:<br>-g sets the keyframe interval.<br>-keyint_min sets the minimum keyframe interval.<br>-x264-params “keyint=x:min-keyint=y” is the same as -g x -keyint_min y.<br>Note: When setting both to the same value, the minimum is internally set to half the maximum interval plus one, as seen in the x264 code:<br>h-&gt;param.i_keyint_min = x264_clip3( h-&gt;param.i_keyint_min, 1, h-&gt;param.i_keyint_max/2+1 );<br>libx265:<br>-g is not implemented.<br>-x265-params “keyint=x:min-keyint=y” works.<br>libvpx-vp9:<br>-g sets the keyframe interval.<br>-keyint_min sets the minimum keyframe interval<br>Note: Due to how FFmpeg works, -keyint_min is only forwarded to the encoder when it is the same as -g. In the code from libvpxenc.c in FFmpeg we can find:<br>if (avctx-&gt;keyint_min &gt;= 0 &amp;&amp; avctx-&gt;keyint_min == avctx-&gt;gop_size) enccfg.kf_min_dist = avctx-&gt;keyint_min; if (avctx-&gt;gop_size &gt;= 0) enccfg.kf_max_dist = avctx-&gt;gop_size;<br>This might be a bug (or lack of feature?), since libvpx definitely supports setting a different value for kf_min_dist.</p>
<h2 id="libx264为DASH转码"><a href="#libx264为DASH转码" class="headerlink" title="libx264为DASH转码"></a>libx264为DASH转码</h2><p>x264 –output intermediate_2400k.264 –fps 24 –preset slow –bitrate 2400 –vbv-maxrate 4800 –vbv-bufsize 9600 –min-keyint 48 –keyint 48 –scenecut 0 –no-scenecut –pass 1 –video-filter “resize:width=1280,height=720” inputvideo.mkv</p>
<p>MP4Box -add intermediate.264 -fps 24 output_2400k.mp4</p>
<p>MP4Box -dash 4000 -frag 4000 -rap -segment-name segment_ output_2400k.mp4</p>
<p>MP4Box -dash 4000 -frag 4000 -rap -segment-name segment_ video.mp4#audio</p>
<h2 id="I帧和IDR帧的区别"><a href="#I帧和IDR帧的区别" class="headerlink" title="I帧和IDR帧的区别"></a>I帧和IDR帧的区别</h2><p>Instantaneous Decoder Refresh (IDR) frames: These allow independent decoding of the following frames, without access to frames previous to the IDR frame.<br>Non-IDR-frames: These require a previous IDR frame for the decoding to work. Non-IDR frames can be used for scene cuts in the middle of a GOP (group of pictures).</p>
<p>An IDR frame is a special type of I-frame in H.264. An IDR frame specifies that no frame after the IDR frame can reference any frame before it. This makes seeking the H.264 file easier and more responsive in the player.</p>
<p>GOP boundary: between two IDR frames</p>
<p>IDR帧是一类特殊的I帧，IDR帧之后的帧都不能参考IDR帧之前的内容</p>
<p>两个IDR帧之间的区域称为GOP，group of pictures</p>
<p>开启scene cut后，GOP内有可能被插入新的非IDR帧的I帧</p>
<p>scenecut 场景切换<br>x264有一指标，用于衡量每一帧与前一帧的差异程度。<br>若该值小于scenecut，则检测到’场景切换’(‘scenecut’)条件，<br>并放置一个I帧 (前提：该帧与上一个IDR帧的间隔小于min-keyint，否则就放置一个IDR帧)。<br>提高scenecut值将增加检测到的’场景切换’数量。<br>ffmpeg中使用-sc_threshold设置此项。<br>将scenecut设为0，相当于设定 no-scenecut</p>
<p>转码DASH时为了I帧的稳定，需要关闭场景切换。</p>
<h2 id="ffmpeg提取音频"><a href="#ffmpeg提取音频" class="headerlink" title="ffmpeg提取音频"></a>ffmpeg提取音频</h2><p>ffmpeg -i input.mkv # show stream numbers and formats<br>ffmpeg -i input.mkv -c copy audio.m4a # AAC<br>ffmpeg -i input.mkv -c copy audio.mp3 # MP3<br>ffmpeg -i input.mkv -c copy audio.ac3 # AC3<br>ffmpeg -i input.mkv -an -c copy video.mkv<br>ffmpeg -i input.mkv -map 0:1 -c copy audio.m4a # stream 1</p>
<h2 id="ffmpeg制作hls切片"><a href="#ffmpeg制作hls切片" class="headerlink" title="ffmpeg制作hls切片"></a>ffmpeg制作hls切片</h2><p>ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8</p>
<h2 id="media-source中切换track"><a href="#media-source中切换track" class="headerlink" title="media source中切换track"></a>media source中切换track</h2><p>SourceBuffer.videoTracks[I].selected = true/false</p>
<h2 id="用MediaSource播放MP4的要求"><a href="#用MediaSource播放MP4的要求" class="headerlink" title="用MediaSource播放MP4的要求"></a>用MediaSource播放MP4的要求</h2><p>MSE(Media Source Extensions)需要mp4中将moov放在文件开始，并有moof（movie fragment box ）在mdat(media data box)前面</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://bathingsun.xyz/2020/01/01/Media-%E7%9B%B8%E5%85%B3-Tips/" data-id="ckhk3e0p40000lbs31pyr1tq4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/10/%E5%A6%82%E4%BD%95%E8%B0%83%E6%95%99%E4%B8%80%E5%8F%B0%E5%AE%8C%E7%BE%8E%E6%B5%8B%E8%AF%95%E6%9C%BA/">如何调教一台完美的测试机:AOSP刷入GMS记录</a>
          </li>
        
          <li>
            <a href="/2020/10/16/%E8%A7%84%E5%88%99%E5%8C%B9%E9%85%8D%E5%BC%95%E6%93%8E/">规则匹配引擎</a>
          </li>
        
          <li>
            <a href="/2020/09/22/Android-WebView-DrawFn-%E7%9B%B8%E5%85%B3/">Android WebView DrawFn 相关</a>
          </li>
        
          <li>
            <a href="/2020/01/01/Media-%E7%9B%B8%E5%85%B3-Tips/">Media 相关 Tips</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 MonkD404<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>